{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUkNiSRHQLVo+FJb+58OBc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chathumal93/ADB-EARR-T4/blob/main/Building_Stability_Monitoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup\n",
        "Run below code to intall all the additional packages needed for this notebook."
      ],
      "metadata": {
        "id": "E00VFQlHoJw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing Necessary packages\n",
        "%%capture\n",
        "!pip install rtree\n",
        "!pip install git+git://github.com/geopandas/geopandas.git\n",
        "!pip install leafmap\n",
        "!pip install keplergl\n",
        "!pip install mapclassify\n",
        "!pip install contextily"
      ],
      "metadata": {
        "id": "amG69nK_y2Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required modules\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from shapely.geometry import Point\n",
        "import geopandas\n",
        "from geopandas import GeoDataFrame\n",
        "import leafmap\n",
        "from scipy.spatial import KDTree\n",
        "import contextily as cx\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "REcpI9broQLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below code to ingest all the required data for this practial task into google colab system for further processing."
      ],
      "metadata": {
        "id": "pVUWFwbOHI2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning the git repository to access the data \n",
        "!git clone https://github.com/chathumal93/ADB-EARR-T4.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rM2t4m7jGnE",
        "outputId": "799128f9-784b-42e6-b626-a1fa9b768471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ADB-EARR-T4'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 41 (delta 18), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (41/41), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the data.zip file to ADB-EARR-T4 folder\n",
        "with zipfile.ZipFile('/content/ADB-EARR-T4/Data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/ADB-EARR-T4')"
      ],
      "metadata": {
        "id": "PV4ASV66j9LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Geohazard Exploitation Platform Results\n"
      ],
      "metadata": {
        "id": "DMLN0HXKlenF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below code to access the **GEP PSI** data in CSV format."
      ],
      "metadata": {
        "id": "jEXTbAEyOiWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing the SNAPPING PSI products\n",
        "# Data in Ascending direction\n",
        "PSI_Asc = '/content/ADB-EARR-T4/1_GEP_SNAPPING_PSI_Data/GEP_SNAPPING_PSI_20181016_20210906_ASC.csv'\n",
        "\n",
        "# Data in Descending direction\n",
        "PSI_Des = '/content/ADB-EARR-T4/1_GEP_SNAPPING_PSI_Data/GEP_SNAPPING_PSI_20181110_20210814_DES.csv'"
      ],
      "metadata": {
        "id": "0owehY4ipBw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below code to read the **Building dataset** and the **Gridded AOI** in shape file format as geodataframes."
      ],
      "metadata": {
        "id": "12m_8P6hnotJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the BIG Building file as a geodataframe.(A clipped Section from the BIG 2019 bulding data set included in the project geoportal)\n",
        "Palu_Bld = geopandas.read_file('/content/ADB-EARR-T4/3_BLD_Data/building_utm_extended_v7_clip.shp')\n",
        "\n",
        "# Reading Gridded AOi as a geodataframe\n",
        "Palu_Grid = geopandas.read_file('/content/ADB-EARR-T4/3_BLD_Data/building_utm_extended_v7_clip_grid.shp')"
      ],
      "metadata": {
        "id": "Q8xLg3LrRZBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below code to define the function, which converts the GEP PSI product into a dataframe"
      ],
      "metadata": {
        "id": "PxbdgyzdP67Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for CSV to Dataframe conversion (PSI-result)\n",
        "def csv2df(csv_file_path):\n",
        "  \"\"\"\n",
        "  This function converts the GEP PSI products in to a dataframe\n",
        "  \"\"\"\n",
        "  # Read PSI data in csv format into a dataframe\n",
        "  data = pd.read_csv(csv_file_path,sep=';',skiprows=16)\n",
        "  \n",
        "  # Image list (dates) in the csv\n",
        "  slv_img_list = list(data.columns)[6:]\n",
        "                              \n",
        "  # Renaming the columns\n",
        "  column_names_01 = ['ID','Lat','Lon','V_LOS','V_STD','INC_ANG']\n",
        "\n",
        "  # Image name list with date\n",
        "  column_names_02 = []\n",
        "\n",
        "  # Re-arranging the column names (This is based on the EARR project geo-portal visualization requirement)\n",
        "  # Getting the date tag of images\n",
        "  for datetime_tag in range(len(slv_img_list)):\n",
        "      column_names_02.append('DL'+ str(slv_img_list[datetime_tag]))\n",
        "\n",
        "  # Final Column names for the dataframe    \n",
        "  column_all = column_names_01 + column_names_02\n",
        "\n",
        "  # Final Dataframe creation with the arranged data and column names\n",
        "  data.columns = column_all\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "IyeFvCPatceG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below code to convert PSI Ascending and Descending product to dataframes (**df_Asc** and **df_Des**)."
      ],
      "metadata": {
        "id": "r0AYAp1HSKNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting PSI ASc CSV file as df_Asc dataframe\n",
        "df_Asc = csv2df(PSI_Asc)\n",
        "\n",
        "# Converting PSI Des CSV file as df_Des dataframe\n",
        "df_Des = csv2df(PSI_Des)"
      ],
      "metadata": {
        "id": "sg0IXLc9O5qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Insights\n",
        "\n",
        "Beofre plotting the PSI data geometrically in both directions, distribution of **Line of Sight (LoS) Velocity** in each direction, is displayed from the following code."
      ],
      "metadata": {
        "id": "ySIdFgfw4-Fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ploting histograms of PSI LOS data in Ascending and Descending directions\n",
        "fig, axes = plt.subplots(1,2,figsize=(15,5))\n",
        "# Ascending\n",
        "sns.histplot(ax=axes[0], data=df_Asc[\"V_LOS\"])\n",
        "axes[0].set_title('PSI Ascending')\n",
        "# Descending\n",
        "sns.histplot(ax=axes[1], data=df_Des[\"V_LOS\"])\n",
        "axes[1].set_title('PSI Descending')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "El00-6uDRsVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PSI LOS Velocity Statistics considering the whole coverage (Asc)\n",
        "df_Asc[\"V_LOS\"].describe()"
      ],
      "metadata": {
        "id": "nD-R70xN5bnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PSI LOS Velocity Statistics considering the whole coverage (Des)\n",
        "df_Des[\"V_LOS\"].describe()"
      ],
      "metadata": {
        "id": "TG1WNbb_5br5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization\n",
        "\n",
        "In this section, all the data will be converted into a format (**geodataframe**) which can be mapped in a static or interactive environment.\n"
      ],
      "metadata": {
        "id": "Wv9QZfvNyNu0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below code to define the function, which converts the PSI dataframe into a geodataframe in **EPSG:32750** projected coordinate system"
      ],
      "metadata": {
        "id": "IvIdqHWxX0HM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def df2gdf_utm(df):\n",
        "  \"\"\"\n",
        "  This function converts the data frame  in to a geodataframe based on WGS 84 / UTM zone 50S\n",
        "  df: dataframe of PSI data (Asc/Des)\n",
        "  \"\"\"\n",
        "  # Accessing the Lat and Long from dataframe for geometry conversion\n",
        "  geometry = [Point(xy) for xy in zip(df.Lon, df.Lat)]\n",
        "  gdf = GeoDataFrame(df, crs=\"EPSG:4326\", geometry=geometry)\n",
        "\n",
        "  # Coverting gdf from EPSG:4326 to EPSG:32750 â€“ WGS 84 / UTM zone 50S\n",
        "  # For the stabilty analysis the points needs to be in meter(m) format\n",
        "  gdf_utm = gdf.to_crs(\"EPSG:32750\")\n",
        "\n",
        "  return gdf_utm"
      ],
      "metadata": {
        "id": "zxvkE0MJMoSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below code to use the above function and convert Ascending and Desceding PSI dataframes into geodataframes."
      ],
      "metadata": {
        "id": "tWrOIFvVZDW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting df_Asc dataframe into gdf_Asc geodataframe\n",
        "gdf_Asc = df2gdf_utm(df_Asc)\n",
        "\n",
        "# Converting df_Des dataframe into gdf_Des geodataframe\n",
        "gdf_Des = df2gdf_utm(df_Des)"
      ],
      "metadata": {
        "id": "XdE_SnncMsdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below code to plot **gdf_Asc** and **gdf_Des** geodataframes into static maps."
      ],
      "metadata": {
        "id": "9oUed6Z3Z0WP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading PSI values within Palu_Grid\n",
        "gdf_2_plot_A = geopandas.overlay(gdf_Asc, Palu_Grid, how='intersection')\n",
        "gdf_2_plot_D = geopandas.overlay(gdf_Des, Palu_Grid, how='intersection')\n",
        "\n",
        "# Conversion of projection to match with basemap\n",
        "gdf_2_plot_A = gdf_2_plot_A.to_crs(epsg=3857)\n",
        "gdf_2_plot_D = gdf_2_plot_D.to_crs(epsg=3857)\n",
        "\n",
        "# Plotting the PSI products \n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, sharey=True,figsize=(15,10))\n",
        "# Map for Ascending product\n",
        "map01 = gdf_2_plot_A.plot(ax=ax1,column=\"V_LOS\",figsize=(10,10),cmap='RdYlBu',legend=True,scheme='User_Defined',k=5,markersize=1,classification_kwds=dict(bins=[-15,-10,-5,0,5,10,15])) \n",
        "ax1.title.set_text('Ascending')\n",
        "cx.add_basemap(map01, source=cx.providers.CartoDB.Voyager)\n",
        "\n",
        "# Map for Descending product\n",
        "map02 =gdf_2_plot_D.plot(ax=ax2,column=\"V_LOS\",figsize=(10,10),cmap='RdYlBu',legend=True,scheme='User_Defined',k=5,markersize=1,classification_kwds=dict(bins=[-15,-10,-5,0,5,10,15])) \n",
        "ax2.title.set_text('Descending')\n",
        "cx.add_basemap(map02, source=cx.providers.CartoDB.Voyager)"
      ],
      "metadata": {
        "id": "-J8TKmYQxrtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below to visualize the **Gridded AOI** in a interactive web map. Based on this grid system, building motion analyze can be done in the next section."
      ],
      "metadata": {
        "id": "d9KsvePbabXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from leafmap import basemaps\n",
        "import leafmap.kepler as leafmap\n",
        "\n",
        "# Initiating a map object\n",
        "map01 = leafmap.Map(center=(-0.88, 119.86), zoom=11, height=500)\n",
        "# Adding grid geodataframe to map object\n",
        "map01.add_gdf(Palu_Grid, layer_name=\"Grid\")\n",
        "# Displaying map\n",
        "map01 "
      ],
      "metadata": {
        "id": "GYKjjBeQ5X7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "User can select a plot from the **Gridded AOI/Palu_Grid**. Based on the attributes(**'PageName'**) of the Gridded AOI, user will be able to  get all the buildings belong to that selected plot. In this notebook plot E3 is selected and processed further."
      ],
      "metadata": {
        "id": "qPzHjd_kcMkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting a plot from the grid for the building motion analyze and select all the building in the selected slot\n",
        "slot = Palu_Grid.loc[Palu_Grid['PageName'] == \"E3\"]\n",
        "\n",
        "# Building selection whithin in the plot\n",
        "Palu_Bld_slot = geopandas.overlay(Palu_Bld, slot, how='intersection')"
      ],
      "metadata": {
        "id": "FRSJBAnQFskc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below to visualize the **Selected Buildings** in a different interactive web map format."
      ],
      "metadata": {
        "id": "8FkPRoz0eGiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the selected building within the the defined plot\n",
        "# Initiating a map object\n",
        "map02 = leafmap.Map(center=(-0.88, 119.86), zoom=11, height=500)\n",
        "# Adding grid geodataframe to map object\n",
        "map02.add_gdf(Palu_Bld_slot, layer_name=\"Buildings_subset\")\n",
        "# Displaying map\n",
        "map02"
      ],
      "metadata": {
        "id": "4d_fP8Rp7S-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOS Velocity Interpolation\n",
        "\n",
        "In this section Nearest **Neighbour Interpolation** approach is used to assign LOS velocity vlaues of persistence scatterers to the building dataset.\n",
        "**PSI** data in the **Ascending** direction is selected for further analyze."
      ],
      "metadata": {
        "id": "2jAhO3JUq3uY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the selected Geodataframe as PSI variable\n",
        "PSI = gdf_Asc"
      ],
      "metadata": {
        "id": "2gx5iv2jFGxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign displacement range 30 mm to -30 mm\n",
        "PSI = PSI.loc[(PSI['V_LOS']>=-30) | (PSI['V_LOS']<=30)]\n",
        "\n",
        "# Getting PSI UTM 50S co-ordinates\n",
        "PSI_coordts = []\n",
        "for row in PSI['geometry']:\n",
        "    PSI_LON = float(str(row).split('POINT (')[1].split(')')[0].split(' ')[0])\n",
        "    PSI_LAT = float(str(row).split('POINT (')[1].split(')')[0].split(' ')[1])\n",
        "    PSI_coordts.append([PSI_LON,PSI_LAT])\n",
        "    \n",
        "PSI_coordts = np.array(PSI_coordts)"
      ],
      "metadata": {
        "id": "9OjKterp_H9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below codes to estimate centroid for each building in **Palu_Bld** layer.\n",
        "\n"
      ],
      "metadata": {
        "id": "Rxsz5gfajGoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building centroid estimation\n",
        "# Reading the Buildings as a geodataframe from the selected grid plot\n",
        "# If needed the whole buidling layer, Palu_Bld.copy() can be used\n",
        "BLD_CEN = Palu_Bld_slot.copy()"
      ],
      "metadata": {
        "id": "Naboe2PKlVcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the centroid\n",
        "BLD_CEN.geometry = BLD_CEN['geometry'].centroid\n",
        "# Define the coordinate system for the new geodataframe\n",
        "BLD_CEN.crs = Palu_Bld.crs"
      ],
      "metadata": {
        "id": "s40F6Fion5ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Building centroid co-ordinates to a numpy array : B_coordts --> [[Lon,Lat]]\n",
        "B_coordts = []\n",
        "for row in BLD_CEN['geometry']:\n",
        "    B_LON = float(str(row).split('POINT (')[1].split(')')[0].split(' ')[0])\n",
        "    B_LAT = float(str(row).split('POINT (')[1].split(')')[0].split(' ')[1])\n",
        "    B_coordts.append([B_LON,B_LAT])  \n",
        "B_coordts = np.array(B_coordts)"
      ],
      "metadata": {
        "id": "C7F8gdhDJytC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below code to define the function, which execute the **Nearest Neighbour** interpolation of **PSI data** based on the location of **building centroids**."
      ],
      "metadata": {
        "id": "Vvt3r8jBmboy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLVGts9XvKLz"
      },
      "outputs": [],
      "source": [
        "def NN_buf_KDTree(New_CO,Old_V,Old_CO,buffer_m):\n",
        "\n",
        "  \"\"\"\n",
        "  This function assigns the nearest neighbour value for a new point based on the defined distance from a old point which has the location and value components.\n",
        "\n",
        "  New_CO : Coordinates of new points (to assign the interpolated data)\n",
        "  Old_CO : Coordinates of old points\n",
        "  Old_V : Values of old points to be interpolated\n",
        "  buffer_m : Buffer distance in meters\n",
        "  \"\"\"  \n",
        "  Tree = KDTree(Old_CO,)\n",
        "\n",
        "  NN_Buff_Values = []\n",
        "  for item in range(len(New_CO)):\n",
        "\n",
        "    dd, ii = Tree.query(New_CO[item], k=1)\n",
        "\n",
        "    # [distance , index]\n",
        "    dd_ii = np.c_[dd,ii]\n",
        "\n",
        "    if (dd_ii[0,0] <= buffer_m) & (dd_ii[0,0] >= 0):\n",
        "      intpl_value = Old_V[int(dd_ii[0][1])][0]\n",
        "      NN_Buff_Values.append(intpl_value)\n",
        "\n",
        "    else :\n",
        "      intpl_value = -9999\n",
        "      NN_Buff_Values.append(intpl_value)\n",
        "\n",
        "  return NN_Buff_Values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting PSI ground motion values to a numpy array : PSI_values --> [V1,...,Vn]\n",
        "PSI_values = np.array(PSI.V_LOS)\n",
        "\n",
        "# Arranging arrays according to the NN_buf_KDTree function  : xyz --> [[Lon,Lat,Velocity]]\n",
        "xyz = np.c_[PSI_coordts,PSI_values]\n",
        "\n",
        "# PSI_vel: [[V1],[V2]....,[Vn]]\n",
        "PSI_vel = xyz[:,2:]"
      ],
      "metadata": {
        "id": "kNnfWw_-vyFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting new (interpolated) values to building centroids\n",
        "interpolated_vals = NN_buf_KDTree(B_coordts,PSI_vel,PSI_coordts,100)\n",
        "interpolated_vals = np.array(interpolated_vals)"
      ],
      "metadata": {
        "id": "SeFt_xMqNCtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Stability Classification"
      ],
      "metadata": {
        "id": "1c5_0SD4NNOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpolated LOS Velcity values of building centriods are used in the classification process."
      ],
      "metadata": {
        "id": "iHZMRIDSxDzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on the standard deviation of V_LOS values, levels of motion can be defined.\n",
        "# STD value for Asc PSI product\n",
        "std_val = np.std(df_Asc[\"V_LOS\"])\n",
        "mean_val = np.mean(df_Asc[\"V_LOS\"])\n",
        "\n",
        "#Medium motion : 2*std to 1*std\n",
        "#Low motion : 1*std to -1*std\n",
        "#High motion : >2*std and <-2*std\n",
        "\n",
        "positive_l =  mean_val+(1*std_val)\n",
        "positive_h =  mean_val+(2*std_val)\n",
        "negative_l = mean_val+(-1*std_val)\n",
        "negative_h = mean_val+(-2*std_val)\n",
        "no_Data = -9999.0"
      ],
      "metadata": {
        "id": "SoQF8Bq2Snck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below code to classify the interpolated motion values in to three main categories **Low, Medium** and **High**. Building centroids without any interpolated values, will be classified as no data."
      ],
      "metadata": {
        "id": "vHz0AWx6rOeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intiating a null array for interpolated values\n",
        "b_i = np.array([])\n",
        "\n",
        "# Classification base on the PSI value distribution\n",
        "for i in interpolated_vals:\n",
        "  if (i == no_Data):\n",
        "    b_i = np.append(b_i,'nan')           \n",
        "  elif ((i >= negative_l) and (i <= positive_l)): \n",
        "    b_i = np.append(b_i,'Low')     \n",
        "  elif ((i < negative_l) and (i >= negative_h)):\n",
        "    b_i = np.append(b_i,'Medium')             \n",
        "  elif ((i > positive_l) and (i <= positive_h)):        \n",
        "    b_i = np.append(b_i,'Medium')               \n",
        "  elif ((i < negative_h) or (i > positive_h)):            \n",
        "    b_i = np.append(b_i,'High')             \n",
        "  else:\n",
        "    b_i = np.append(b_i,no_Data)"
      ],
      "metadata": {
        "id": "h_lK6rwHu70s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decription of the data\n",
        "values, counts = np.unique(b_i, return_counts=True)\n",
        "print('values:',values, \"count: \",counts) "
      ],
      "metadata": {
        "id": "gDx3K-5m2zL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attaching interpolated values to building section\n",
        "#Creating a copy of a selected building plot\n",
        "Palu_Bld_slot_motion = Palu_Bld_slot.copy()\n",
        "\n",
        "Palu_Bld_slot_motion['Vel_mm']  = pd.Series(interpolated_vals)\n",
        "Palu_Bld_slot_motion['motion'] = pd.Series(b_i)"
      ],
      "metadata": {
        "id": "v6yl15X_qNFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Geodataframe information\n",
        "Palu_Bld_slot_motion.head()"
      ],
      "metadata": {
        "id": "5GuATOpn97mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Product\n",
        "Run the below code to visualize the processed building stability layer in a web map."
      ],
      "metadata": {
        "id": "AkwwPChfNbEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of the final product\n",
        "# Initiating a map object\n",
        "map03 = leafmap.Map(center=(-0.88, 119.86), zoom=11, height=500)\n",
        "# Adding grid geodataframe to map object\n",
        "map03.add_gdf(Palu_Bld_slot_motion, layer_name=\"Building_motion\")\n",
        "# Displaying map\n",
        "map03"
      ],
      "metadata": {
        "id": "TXKyKAVrj5sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below code to create a result folder to store processed data"
      ],
      "metadata": {
        "id": "ZIcqFH59ylgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a result folder to store the results for visualization\n",
        "if not os.path.exists('/content/ADB-EARR-T4/4_Results'):\n",
        "  os.makedirs('/content/ADB-EARR-T4/4_Results')"
      ],
      "metadata": {
        "id": "zGX3B0UI445K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below code export selected GEP PSI product in a shape file format"
      ],
      "metadata": {
        "id": "1GCiOXcR0rVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Below code can be used to covert the geodataframe to a shape file in Google Colab drive and the file can be downloaded to local computer.\n",
        "# Export gdf as a shp\n",
        "gdf_Asc.to_file('/content/ADB-EARR-T4/4_Results/GEP_SNAPPING_PSI_20181016_20210906_ASC.shp')\n",
        "# create a ZipFile object\n",
        "zipObj = zipfile.ZipFile('/content/ADB-EARR-T4/4_Results/GEP_SNAPPING_PSI_20181016_20210906_ASC.zip', 'w')\n",
        "\n",
        "# Add multiple files to the zip\n",
        "zipObj.write('/content/ADB-EARR-T4/4_Results/GEP_SNAPPING_PSI_20181016_20210906_ASC.dbf',arcname='GEP_SNAPPING_PSI_20181016_20210906_ASC.dbf')\n",
        "zipObj.write('/content/ADB-EARR-T4/4_Results/GEP_SNAPPING_PSI_20181016_20210906_ASC.prj',arcname='GEP_SNAPPING_PSI_20181016_20210906_ASC.prj')\n",
        "zipObj.write('/content/ADB-EARR-T4/4_Results/GEP_SNAPPING_PSI_20181016_20210906_ASC.shp',arcname='GEP_SNAPPING_PSI_20181016_20210906_ASC.shp')\n",
        "zipObj.write('/content/ADB-EARR-T4/4_Results/GEP_SNAPPING_PSI_20181016_20210906_ASC.shx',arcname='GEP_SNAPPING_PSI_20181016_20210906_ASC.shx')\n",
        "\n",
        "# close the Zip File\n",
        "zipObj.close()\n",
        "\n",
        "# Downloading the GEP SNAPPING PSI product to local machine\n",
        "#files.download('/content/ADB-EARR-T4/4_Results/GEP_SNAPPING_PSI_20181016_20210906_ASC_SHP.zip')"
      ],
      "metadata": {
        "id": "O8hVxhF5wXe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below code export final GEP PSI Building Stability product in shape file format"
      ],
      "metadata": {
        "id": "WTsTxFjf1iBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Below code can be used to covert the geodataframe (building motion) to a shape file in Google Colab drive and the file can be downloaded to local computer.\n",
        "# Export gdf as a shp\n",
        "Palu_Bld_slot_motion.to_file('/content/ADB-EARR-T4/4_Results/GEP_SNAPPING_PSI_BLD_STB.shp')\n",
        "# create a ZipFile object\n",
        "zipObj = zipfile.ZipFile('/content/ADB-EARR-T4/4_Results/GEP_SNAPPING_PSI_BLD_STB.zip', 'w')\n",
        "\n",
        "# Add multiple files to the zip\n",
        "zipObj.write('/content/ADB-EARR-T4/4_Results/GEP_SNAPPING_PSI_BLD_STB.dbf',arcname='GEP_SNAPPING_PSI_BLD_STB.dbf')\n",
        "zipObj.write('/content/ADB-EARR-T4/4_Results/GEP_SNAPPING_PSI_BLD_STB.prj',arcname='GEP_SNAPPING_PSI_BLD_STB.prj')\n",
        "zipObj.write('/content/ADB-EARR-T4/4_Results/GEP_SNAPPING_PSI_BLD_STB.shp',arcname='GEP_SNAPPING_PSI_BLD_STB.shp')\n",
        "zipObj.write('/content/ADB-EARR-T4/4_Results/GEP_SNAPPING_PSI_BLD_STB.shx',arcname='GEP_SNAPPING_PSI_BLD_STB.shx')\n",
        "\n",
        "# close the Zip File\n",
        "zipObj.close()\n",
        "\n",
        "# Downloading the GEP SNAPPING PSI Building motion product to local machine\n",
        "#files.download('/content/ADB-EARR-T4/4_Results/GEP_SNAPPING_PSI_BLD_STB.zip')"
      ],
      "metadata": {
        "id": "FKJbbjgu5VHy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}