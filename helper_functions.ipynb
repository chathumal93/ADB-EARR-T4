{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "helper-functions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxfGbpscNr2HbFC2DZX5fR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chathumal93/ADB-EARR-T4/blob/main/helper_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95nUQ36Q0jns"
      },
      "outputs": [],
      "source": [
        "# function for CSV to Dataframe conversion (PSI-result)\n",
        "def psi_csv2df(csv_file_path):\n",
        "  \"\"\"\n",
        "  This function converts the GEP PSI products in to a dataframe\n",
        "  \"\"\"\n",
        "  # Read PSI data in csv format into a dataframe\n",
        "  data = pd.read_csv(csv_file_path,sep=';',skiprows=16)\n",
        "  \n",
        "  # Image list (dates) in the csv\n",
        "  slv_img_list = list(data.columns)[6:]\n",
        "                              \n",
        "  # Renaming the columns\n",
        "  column_names_01 = ['ID','Lat','Lon','V_LOS','V_STD','INC_ANG']\n",
        "\n",
        "  # Image name list with date\n",
        "  column_names_02 = []\n",
        "\n",
        "  # Re-arranging the column names (This is based on the EARR project geo-portal visualization requirement)\n",
        "  # Getting the date tag of images\n",
        "  for datetime_tag in range(len(slv_img_list)):\n",
        "      column_names_02.append('DL'+ str(slv_img_list[datetime_tag]))\n",
        "\n",
        "  # Final Column names for the dataframe    \n",
        "  column_all = column_names_01 + column_names_02\n",
        "\n",
        "  # Final Dataframe creation with the arranged data and column names\n",
        "  data.columns = column_all\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function for CSV to Dataframe conversion (PSBAS-result)\n",
        "def sbas_csv2df(csv_file_path):\n",
        "  data = pd.read_csv(csv_file_path,skiprows=43)\n",
        "  # Column Adjusting\n",
        "  column_names_01 = ['ID','Lat','Lon','Topo','V_LOS','COH','cosN','cosE','cosU','TS']\n",
        "\n",
        "  # Getting the image list (Frist image as the base image)\n",
        "  img_list = list(pd.read_csv(csv_file_path, nrows=1, skiprows=39))\n",
        "  slv_img_list = img_list[1:]\n",
        "  # Slave image name list\n",
        "  column_names_02 = []\n",
        "\n",
        "  # Getting the data tag of slave images\n",
        "  for datetime_tag in range(len(slv_img_list)):\n",
        "      date_tag = slv_img_list[datetime_tag].split('T')[0].split(' ')[1]\n",
        "      column_names_02.append('DL'+ date_tag.split('-')[0]+''+date_tag.split('-')[1]+''+date_tag.split('-')[2])    \n",
        "  column_all = column_names_01 + column_names_02\n",
        "  data.columns = column_all\n",
        "\n",
        "  #Conversion for the mm scale\n",
        "  data['V_LOS'] = np.array(data['V_LOS'])*10\n",
        "  #Conversion of displacement to mm scale\n",
        "  for col in column_names_02:\n",
        "    data[col] = np.array(data[col])*10\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "WO-eSsnZ7ZdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df2gdf_utm(df):\n",
        "  \"\"\"\n",
        "  This function converts the data frame  in to a geodataframe based on WGS 84 / UTM zone 50S\n",
        "  df: dataframe of PSI data (Asc/Des)\n",
        "  \"\"\"\n",
        "  # Accessing the Lat and Long from dataframe for geometry conversion\n",
        "  geometry = [Point(xy) for xy in zip(df.Lon, df.Lat)]\n",
        "  gdf = GeoDataFrame(df, crs=\"EPSG:4326\", geometry=geometry)\n",
        "\n",
        "  # Coverting gdf from EPSG:4326 to EPSG:32750 â€“ WGS 84 / UTM zone 50S\n",
        "  # For the stabilty analysis the points needs to be in meter(m) format\n",
        "  gdf_utm = gdf.to_crs(\"EPSG:32750\")\n",
        "\n",
        "  return gdf_utm"
      ],
      "metadata": {
        "id": "OilIqh130ujX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NN_buf_KDTree(New_CO,Old_V,Old_CO,buffer_m,npt):\n",
        "\n",
        "  \"\"\"\n",
        "  This function assigns the nearest neighbour value for a new point based on \n",
        "  the difined distance from a old point which has the location and value components.\n",
        "\n",
        "  New_CO : Coordinates of new points (to assign the interpolated data)\n",
        "  Old_CO : Coordinates of old points\n",
        "  Old_V : Values of old points to be interpolated\n",
        "  buffer_m : Buffer distance in meters\n",
        "  np : number of closest points needed\n",
        "  \"\"\"  \n",
        "  Tree = KDTree(Old_CO,)\n",
        "\n",
        "  NN_Buff_Values = []\n",
        "  for item in range(len(New_CO)):\n",
        "\n",
        "    dd, ii = Tree.query(New_CO[item], k=npt)\n",
        "\n",
        "    # [distance , index]\n",
        "    dd_ii = np.c_[dd,ii]\n",
        "\n",
        "    if (dd_ii[0,0] <= buffer_m) & (dd_ii[0,0] >= 0):\n",
        "      intpl_value = Old_V[int(dd_ii[0][1])][0]\n",
        "      NN_Buff_Values.append(intpl_value)\n",
        "\n",
        "    else :\n",
        "      intpl_value = -9999\n",
        "      NN_Buff_Values.append(intpl_value)\n",
        "\n",
        "  return NN_Buff_Values"
      ],
      "metadata": {
        "id": "Zytjv10J0y2-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}